{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fc754f",
   "metadata": {},
   "source": [
    "## Reproduction of Knowledge Source Integration on Medical Code Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3df601",
   "metadata": {},
   "source": [
    "This bonus Jupyter Notebook was created solely by Robert Zhang (ruihaoz2@illinois.edu), my teammate Hannah Ke agreed to abandon this bonus task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8dd3e6",
   "metadata": {},
   "source": [
    "### 1. Reproducibility Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5667c8d",
   "metadata": {},
   "source": [
    "The original paper proposed a framework called Knowledge Source Integration (KSI) for improving the automatic assignment of ICD-9 diagnosis codes to clinical notes. The KSI framework incorporated external knowledge sources, such as Wikipedia, into the training process of neural network models. The reproducibility project aimed to replicate the original study's findings and evaluate the performance of the KSI framework using the MIMIC-III dataset.\n",
    "\n",
    "The report described the methodology used to replicate the original study, including data preprocessing, model descriptions, and hyperparameter tuning. The authors successfully reproduced the KSI model and demonstrated its effectiveness in improving code prediction accuracy. They compared the performance of KSI models with CNN and LSTM to their respective baseline models without external knowledge integration. The results showed that the KSI models outperformed the baseline models, achieving a 3% increase in accuracy.\n",
    "\n",
    "The report also discussed the challenges faced during reproduction, such as data preprocessing complexities and the difficulty of reproducing the model structure. Recommendations for improving reproducibility included documenting the random seed initialization, providing detailed documentation and instructions, and parameterizing hyperparameters for easier experimentation.\n",
    "\n",
    "In addition, the authors of the reproducibility report communicated with the original authors to clarify certain aspects of the study and ensure a transparent exchange of information. Overall, the report confirms the reproducibility of the original study's findings and highlights the effectiveness of the KSI framework in improving medical code prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e5b1fd",
   "metadata": {},
   "source": [
    "### 2. Data Overview\n",
    "We have three datasets (two main data sources) for the model:\n",
    "* NOTEEVENTS.csv (A clinical notes dataset from the MIMIC-III Critical Care Database)\n",
    "* DIAGNOSES_ICD.csv (The ICD-9 diagnosis codes dataset from the MIMIC-III Database)\n",
    "* wikipedia_knowledge.txt (The external ICD-9 diagnosis codes knowledge dataset from Wikipedia.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ff3f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_NoteEvents = pd.read_csv(\"NOTEEVENTS_Partial.csv\")\n",
    "df_DiagnosesICD = pd.read_csv(\"DIAGNOSES_ICD.csv\")\n",
    "with open(\"wikipedia_knowledge.txt\", 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5efd4c6",
   "metadata": {},
   "source": [
    "Here is the overview of the NOTEEVENTS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd8aabeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>22532</td>\n",
       "      <td>167853</td>\n",
       "      <td>8/4/2151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>13702</td>\n",
       "      <td>107527</td>\n",
       "      <td>6/14/2118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>13702</td>\n",
       "      <td>167118</td>\n",
       "      <td>5/25/2119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>13702</td>\n",
       "      <td>196489</td>\n",
       "      <td>8/18/2124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>26880</td>\n",
       "      <td>135453</td>\n",
       "      <td>3/25/2162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ROW_ID SUBJECT_ID HADM_ID  CHARTDATE CHARTTIME STORETIME           CATEGORY  \\\n",
       "0    174      22532  167853   8/4/2151       NaN       NaN  Discharge summary   \n",
       "1    175      13702  107527  6/14/2118       NaN       NaN  Discharge summary   \n",
       "2    176      13702  167118  5/25/2119       NaN       NaN  Discharge summary   \n",
       "3    177      13702  196489  8/18/2124       NaN       NaN  Discharge summary   \n",
       "4    178      26880  135453  3/25/2162       NaN       NaN  Discharge summary   \n",
       "\n",
       "  DESCRIPTION  CGID  ISERROR  \\\n",
       "0      Report   NaN      NaN   \n",
       "1      Report   NaN      NaN   \n",
       "2      Report   NaN      NaN   \n",
       "3      Report   NaN      NaN   \n",
       "4      Report   NaN      NaN   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
       "2  Admission Date:  [**2119-5-4**]              D...  \n",
       "3  Admission Date:  [**2124-7-21**]              ...  \n",
       "4  Admission Date:  [**2162-3-3**]              D...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NoteEvents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e299f3a",
   "metadata": {},
   "source": [
    "Here is the overview of the DiagnosesICD.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5f8da42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SEQ_NUM</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1297</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1298</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>2.0</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1299</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1300</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1301</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
       "0    1297         109   172335      1.0     40301\n",
       "1    1298         109   172335      2.0       486\n",
       "2    1299         109   172335      3.0     58281\n",
       "3    1300         109   172335      4.0      5855\n",
       "4    1301         109   172335      5.0      4254"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_DiagnosesICD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72c6e6",
   "metadata": {},
   "source": [
    "Here is the overview of the wikipedia_knowledge.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "325eca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXdiseaseXXX   breast cancer  d_174  d_175\n",
      "\n",
      "Breast cancer\n",
      "\n",
      "\n",
      "\n",
      "Breast cancer is cancer that develops from breast tissue. Signs of breast cancer may include a lump in the breast, a change in breast shape, dimpling of the skin, fluid coming from the nipple, a newly inverted nipple, or a red or scaly patch of skin. In those with distant spread of the disease, there may be bone pain, swollen lymph nodes, shortness of breath, or yellow skin.\n",
      "\n",
      "Risk factors for developing breast cancer include being female, obesity, lack of physical exercise, drinking alcohol, hormone replacement therapy during menopause, ionizing radiation, early age at first menstruation, having children late or not at all, older age, prior history of breast cancer, and family history. About 5–10% of cases are due to genes inherited from a person's parents, including BRCA1 and BRCA2 among others. Breast cancer most commonly develops in cells from the lining of milk ducts and the lobules that supply the ducts with milk. Cancers developing from the ducts are known as ductal carcinomas, while those developing from lobules are known as lobular carcinomas. In addition, there are more than 18 other sub-types of breast cancer. Some cancers, such as ductal carcinoma in situ, develop from pre-invasive lesions. The diagnosis of breast cancer is confirmed by taking a biopsy of the concerning lump. Once the diagnosis is made, further tests are done to determine if the cancer has spread beyond the breast and which treatments are most likely to be effective.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in lines[:5]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c90f9a",
   "metadata": {},
   "source": [
    "On average, each visit has 11 medical codes. The code vocabulary contains 942 codes. Of those codes, we selected a subset of 344 codes for which we found the corresponding Wikipedia document and used those codes in our experiments. For Wikipedia knowledge dataset, we found 344 of them in MIMIC-III medical code vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36994db4",
   "metadata": {},
   "source": [
    "### 3. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee712c",
   "metadata": {},
   "source": [
    "In this part, We take one of our model: CNN+KSI as an example. We first load the data, preprocess it, and create batches. Then, we define a CNN model and train it using the loaded data. Finally, we test the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce8aec",
   "metadata": {},
   "source": [
    "#### 3.1 Data Preprocessing\n",
    "The dataset is preprocessed and converted into batches suitable for training and evaluation. This includes:\n",
    "* Converting labels into one-hot vectors\n",
    "* Sorting the data by length\n",
    "* Creating batches with fixed batch size and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77c196c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_data_preprocess(data, batch_size=32):\n",
    "    processed_data = []\n",
    "\n",
    "    # convert labels to vectors\n",
    "    for i, note, j in data:\n",
    "        temp_label = np.zeros(len(lab2ind), dtype=float)\n",
    "        temp_label[[lab2ind[jj] for jj in j if jj in wikivoc]] = 1.0\n",
    "        processed_data.append((i, note, temp_label))\n",
    "\n",
    "    processed_data = np.array(processed_data, dtype=object)\n",
    "\n",
    "    # sort by length of i\n",
    "    lengths = np.array([len(item[0]) for item in processed_data])\n",
    "    sorted_indices = lengths.argsort()\n",
    "    processed_data = processed_data[sorted_indices]\n",
    "\n",
    "    # create batches\n",
    "    batched_data = []\n",
    "    for start_ix in range(0, len(processed_data) - batch_size + 1, batch_size):\n",
    "        block = processed_data[start_ix:start_ix+batch_size]\n",
    "        max_word_num = max(len(item[0]) for item in block)\n",
    "\n",
    "        # create main matrix\n",
    "        main_matrix = np.zeros((len(block), max_word_num), dtype=np.int64)\n",
    "        for i, item in enumerate(block):\n",
    "            ix = [wor2ind[word] for word in item[0][:max_word_num] if word in wor2ind]\n",
    "            main_matrix[i, :len(ix)] = ix\n",
    "\n",
    "        # gather notes and labels\n",
    "        notes = np.array([item[1] for item in block])\n",
    "        labels = np.array([item[2] for item in block])\n",
    "\n",
    "        # wrap in torch variables\n",
    "        batched_data.append((\n",
    "            autograd.Variable(torch.from_numpy(main_matrix)),\n",
    "            autograd.Variable(torch.FloatTensor(notes)),\n",
    "            autograd.Variable(torch.FloatTensor(labels))\n",
    "        ))\n",
    "\n",
    "    return batched_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775d9c3",
   "metadata": {},
   "source": [
    "#### 3.2 Model Architecture\n",
    "The CNN model is designed with the following layers:\n",
    "* An embedding layer with dropout\n",
    "* Convolutional layers with varying kernel sizes\n",
    "* Linear layers for similarity learning\n",
    "* An output layer to generate tag scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5a498c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, batch_size, vocab_size, target_size):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Embedding layer with dropout\n",
    "        self.embeddings = nn.Sequential(\n",
    "            nn.Embedding(vocab_size + 1, embed_size, padding_idx=0),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "        \n",
    "        # Convolutional layers with varying kernel sizes\n",
    "        self.convs1 = nn.Conv1d(embed_size, conv_out, kernel_size[0])\n",
    "        self.convs2 = nn.Conv1d(embed_size, conv_out, kernel_size[1])\n",
    "        self.convs3 = nn.Conv1d(embed_size, conv_out, kernel_size[2])\n",
    "        \n",
    "        # Linear layers\n",
    "        self.hidden2tag = nn.Linear(300, target_size)\n",
    "        self.layer2 = nn.Linear(embed_size, 1, bias=False)\n",
    "        self.embedding = nn.Linear(rvocsize, embed_size)\n",
    "        self.attention = nn.Linear(embed_size, embed_size)\n",
    "        \n",
    "        # Activation function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, vec1, nvec, wiki, simlearning):\n",
    "        # Apply embedding and dropout to the input\n",
    "        x = self.embeddings(vec1).transpose(1, 2)\n",
    "\n",
    "        # Apply convolutional layers\n",
    "        output1 = self.tanh(self.convs1(x))\n",
    "        output1 = nn.MaxPool1d(output1.size()[2])(output1)\n",
    "\n",
    "        output2 = self.tanh(self.convs2(x))\n",
    "        output2 = nn.MaxPool1d(output2.size()[2])(output2)\n",
    "\n",
    "        output3 = self.tanh(self.convs3(x))\n",
    "        output3 = nn.MaxPool1d(output3.size()[2])(output3)\n",
    "\n",
    "        # Concatenating convolutional outputs\n",
    "        output4 = torch.cat([output1, output2, output3], 1).squeeze(2)\n",
    "\n",
    "        # Similarity learning block\n",
    "        if simlearning:\n",
    "            # Expand nvec and wiki to match dimensions\n",
    "            nvec = nvec.view(batch_size, 1, -1).expand(batch_size, wiki.size()[0], -1)\n",
    "            wiki = wiki.view(1, wiki.size()[0], -1).expand(nvec.size())\n",
    "            \n",
    "            # Apply linear layers and activation function\n",
    "            new = self.embedding(wiki * nvec)\n",
    "            attention = self.sigmoid(self.attention(new))\n",
    "            vec3 = self.layer2(new * attention).view(batch_size, -1)\n",
    "            \n",
    "            # Compute final tag scores with similarity learning\n",
    "            tag_scores = self.sigmoid((self.hidden2tag(output4).detach() + vec3))\n",
    "        else:\n",
    "            # Compute final tag scores without similarity learning\n",
    "            tag_scores = self.sigmoid(self.hidden2tag(output4))\n",
    "\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a81f16",
   "metadata": {},
   "source": [
    "#### 3.3 Training the Model\n",
    "Two models are trained in this notebook: 1. Base CNN model 2. CNN model with Knowledge-guided Similarity learning (KSI). For each model, the training process consists of:\n",
    "* Forward pass through the model to generate tag scores\n",
    "* Computing the loss between the generated tag scores and the ground truth\n",
    "* Backward pass to update the model's parameters using the optimizer\n",
    "* The training is done with early stopping to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffc85964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_train_model(model, sim):\n",
    "    print('start_training')\n",
    "    modelsaved = []\n",
    "    modelperform = []\n",
    "    top = 10\n",
    "\n",
    "    bestresults = -1\n",
    "    bestiter = -1\n",
    "    for epoch in range(5000):\n",
    "        model.train()\n",
    "        lossestrain = []\n",
    "\n",
    "        # Training loop\n",
    "        for mysentence in train_data_batch:\n",
    "            model.zero_grad()\n",
    "            targets = mysentence[2].cuda()\n",
    "            tag_scores = model(mysentence[0].cuda(), mysentence[1].cuda(), wikivec.cuda(), sim)\n",
    "            loss = loss_function(tag_scores, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lossestrain.append(loss.data.mean())\n",
    "\n",
    "        print(epoch)\n",
    "        modelsaved.append(copy.deepcopy(model.state_dict()))\n",
    "        print(\"--------------------------\")\n",
    "        model.eval()\n",
    "\n",
    "        recall = []\n",
    "        \n",
    "        # Validation loop\n",
    "        for inputs in val_data_batch:\n",
    "            targets = inputs[2].cuda()\n",
    "            tag_scores = model(inputs[0].cuda(), inputs[1].cuda(), wikivec.cuda(), sim)\n",
    "            loss = loss_function(tag_scores, targets)\n",
    "\n",
    "            targets = targets.data.cpu().numpy()\n",
    "            tag_scores = tag_scores.data.cpu().numpy()\n",
    "\n",
    "            # Compute recall for each validation example\n",
    "            for iii in range(len(tag_scores)):\n",
    "                temp = {iiii: tag_scores[iii][iiii] for iiii in range(len(tag_scores[iii]))}\n",
    "                temp1 = sorted(temp.items(), key=lambda x: x[1], reverse=True)\n",
    "                thistop = int(np.sum(targets[iii]))\n",
    "                hit = sum([1.0 for ii in temp1[:max(thistop, top)] if targets[iii][ii[0]] == 1.0])\n",
    "\n",
    "                if thistop != 0:\n",
    "                    recall.append(hit / thistop)\n",
    "\n",
    "        # Calculate and print validation recall\n",
    "        avg_recall = np.mean(recall)\n",
    "        print(f'validation top-{top} {avg_recall}')\n",
    "\n",
    "        # Update model performance\n",
    "        modelperform.append(avg_recall)\n",
    "        if avg_recall > bestresults:\n",
    "            bestresults = avg_recall\n",
    "            bestiter = len(modelperform) - 1\n",
    "\n",
    "        # Early stopping\n",
    "        if (len(modelperform) - bestiter) > 5:\n",
    "            print(modelperform, bestiter)\n",
    "            return modelsaved[bestiter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f543572",
   "metadata": {},
   "source": [
    "#### 3.4 Testing the Model\n",
    "The performance of the trained models is evaluated on the test dataset using various metrics, including recall, AUC-ROC, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5eaf35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_test_model(modelstate, sim):\n",
    "    model = CNN(batch_size, len(wor2ind), len(lab2ind))\n",
    "    model.cuda()\n",
    "    loss_function = nn.BCELoss()\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize metrics\n",
    "    recall = []\n",
    "    lossestest = []\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "\n",
    "    # Test loop\n",
    "    for inputs in test_data_batch:\n",
    "        targets = inputs[2].cuda()\n",
    "        tag_scores = model(inputs[0].cuda(), inputs[1].cuda(), wikivec.cuda(), sim)\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "\n",
    "        targets = targets.data.cpu().numpy()\n",
    "        tag_scores = tag_scores.data.cpu().numpy()\n",
    "\n",
    "        lossestest.append(loss.data.mean())\n",
    "        y_true.append(targets)\n",
    "        y_scores.append(tag_scores)\n",
    "\n",
    "        # Compute recall for each test example\n",
    "        for iii in range(len(tag_scores)):\n",
    "            temp = {iiii: tag_scores[iii][iiii] for iiii in range(len(tag_scores[iii]))}\n",
    "            temp1 = sorted(temp.items(), key=lambda x: x[1], reverse=True)\n",
    "            thistop = int(np.sum(targets[iii]))\n",
    "            hit = sum([1.0 for ii in temp1[:max(thistop, top)] if targets[iii][ii[0]] == 1.0])\n",
    "\n",
    "            if thistop != 0:\n",
    "                recall.append(hit / thistop)\n",
    "\n",
    "    # Prepare data for metric calculation\n",
    "    y_true = np.concatenate(y_true, axis=0).T\n",
    "    y_scores = np.concatenate(y_scores, axis=0).T\n",
    "    y_true, y_scores = filter_empty_columns(y_true, y_scores)\n",
    "    y_pred = (y_scores > 0.5).astype(np.int64)\n",
    "\n",
    "    # Calculate and print metrics\n",
    "    print('test loss', np.mean([loss.cpu().item() for loss in lossestest]))\n",
    "    print(f'top-{top}', np.mean(recall))\n",
    "    print('macro AUC', roc_auc_score(y_true, y_scores, average='macro'))\n",
    "    print('micro AUC', roc_auc_score(y_true, y_scores, average='micro'))\n",
    "    print('macro F1', f1_score(y_true, y_pred, average='macro'))\n",
    "    print('micro F1', f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b2041a",
   "metadata": {},
   "source": [
    "#### 3.5 Results\n",
    "After running the code, you will see the performance metrics for both the base CNN model and the CNN + KSI model. This will give you an idea of the improvements gained by incorporating similarity learning into the CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01c7d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_batch=func_data_preprocess(train_data)\n",
    "# test_data_batch=func_data_preprocess(test_data)\n",
    "# val_data_batch=func_data_preprocess(val_data)\n",
    "\n",
    "# # Initialize and train the base model\n",
    "# model = CNN(batch_size, len(wor2ind), len(lab2ind))\n",
    "# model.cuda()\n",
    "# loss_function = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "# basemodel = func_train_model(model, 0)\n",
    "# torch.save(basemodel, 'CNN_model')\n",
    "# print(\"--------------------------\")\n",
    "# print('CNN alone:')\n",
    "# func_test_model(basemodel, 0)\n",
    "# print('===============================')\n",
    "\n",
    "# # Initialize and train the KSI model\n",
    "# model = CNN(batch_size, len(wor2ind), len(lab2ind))\n",
    "# model.cuda()\n",
    "# model.load_state_dict(basemodel)\n",
    "# loss_function = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "# KSImodel = func_train_model(model, 1)\n",
    "# torch.save(KSImodel, 'KSI_CNN_model')\n",
    "# print(\"--------------------------\")\n",
    "# print('KSI+CNN:')\n",
    "# func_test_model(KSImodel, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d218e0a",
   "metadata": {},
   "source": [
    "### 4. Key Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eebf03",
   "metadata": {},
   "source": [
    "This project successful reproduce the original KSI model and prove its ability to significantly improve the automatic assignment of ICD-9 diagnosis codes to clinical notes. The KSI framework was modified to reduce running time, and it was found to outperform models that do not use external knowledge sources.\n",
    "\n",
    "Two scenarios were tested: KSI + CNN and KSI + LSTM. In both cases, incorporating KSI with the baseline model (CNN or LSTM) resulted in a 3% increase in overall accuracy. This demonstrates the potential of leveraging external sources to improve the accuracy of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2dbc977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation</th>\n",
       "      <th>CNN Alone</th>\n",
       "      <th>CNN + KSI</th>\n",
       "      <th>LSTM Alone</th>\n",
       "      <th>LSTM + KSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test loss</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top 10 acc</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.7801</td>\n",
       "      <td>0.7617</td>\n",
       "      <td>0.7901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Macro AUC</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.8659</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Micro AUC</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.9758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Macro F1</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.2447</td>\n",
       "      <td>0.1996</td>\n",
       "      <td>0.2471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Micro F1</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>0.6445</td>\n",
       "      <td>0.6423</td>\n",
       "      <td>0.6552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Evaluation  CNN Alone  CNN + KSI  LSTM Alone  LSTM + KSI\n",
       "0   Test loss     0.0387     0.0366      0.0341      0.0318\n",
       "1  Top 10 acc     0.7553     0.7801      0.7617      0.7901\n",
       "2   Macro AUC     0.8323     0.8659      0.8360      0.8710\n",
       "3   Micro AUC     0.9675     0.9737      0.9687      0.9758\n",
       "4    Macro F1     0.2199     0.2447      0.1996      0.2471\n",
       "5    Micro F1     0.6289     0.6445      0.6423      0.6552"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_data = {\n",
    "    \"Evaluation\": [\"Test loss\", \"Top 10 acc\", \"Macro AUC\", \"Micro AUC\", \"Macro F1\", \"Micro F1\"],\n",
    "    \"CNN Alone\": [0.0387, 0.7553, 0.8323, 0.9675, 0.2199, 0.6289],\n",
    "    \"CNN + KSI\": [0.0366, 0.7801, 0.8659, 0.9737, 0.2447, 0.6445],\n",
    "    \"LSTM Alone\": [0.0341, 0.7617, 0.8360, 0.9687, 0.1996, 0.6423],\n",
    "    \"LSTM + KSI\": [0.0318, 0.7901, 0.8710, 0.9758, 0.2471, 0.6552],\n",
    "}\n",
    "df_Results = pd.DataFrame(table_data)\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ba04c",
   "metadata": {},
   "source": [
    "Hyperparameter tuning was also performed, testing variations in embedding size, hidden dimension, and other parameters. It was concluded that the original hyperparameter settings were already optimized, and changing them did not yield better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb92f32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Small</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test loss</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.7424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top 10 acc</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.7801</td>\n",
       "      <td>0.0525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Macro AUC</td>\n",
       "      <td>0.5037</td>\n",
       "      <td>0.8659</td>\n",
       "      <td>0.4958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Micro AUC</td>\n",
       "      <td>0.4266</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.5798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Macro F1</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.2447</td>\n",
       "      <td>0.0205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Micro F1</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.6445</td>\n",
       "      <td>0.0430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hyperparameters   Small  Origin   Large\n",
       "0       Test loss  0.7330  0.0366  0.7424\n",
       "1      Top 10 acc  0.0160  0.7801  0.0525\n",
       "2       Macro AUC  0.5037  0.8659  0.4958\n",
       "3       Micro AUC  0.4266  0.9737  0.5798\n",
       "4        Macro F1  0.0142  0.2447  0.0205\n",
       "5        Micro F1  0.0297  0.6445  0.0430"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Hyperparameters\": [\"Test loss\", \"Top 10 acc\", \"Macro AUC\", \"Micro AUC\", \"Macro F1\", \"Micro F1\"],\n",
    "    \"Small\": [0.7330, 0.0160, 0.5037, 0.4266, 0.0142, 0.0297],\n",
    "    \"Origin\": [0.0366, 0.7801, 0.8659, 0.9737, 0.2447, 0.6445],\n",
    "    \"Large\": [0.7424, 0.0525, 0.4958, 0.5798, 0.0205, 0.0430]\n",
    "}\n",
    "df_hyperparameters = pd.DataFrame(data)\n",
    "df_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e86ec91",
   "metadata": {},
   "source": [
    "### 5. Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84fa89",
   "metadata": {},
   "source": [
    "1. Bai, T., & Vucetic, S. (2019). Improving Medical Code Prediction from Clinical Text via Incorporating Online Knowledge Sources. In *The World Wide Web Conference (WWW '19)*. Association for Computing Machinery, New York, NY, USA, 72–82. https://doi.org/10.1145/3308558.3313485\n",
    "\n",
    "2. Avati, A., Jung, K., Harman, S., Downing, L., Ng, A., & Shah, N. H. (2017). Improving palliative care with deep learning. In *Bioinformatics and Biomedicine (BIBM), 2017 IEEE International Conference on*. IEEE, 311–316.\n",
    "\n",
    "3. Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. *arXiv preprint arXiv:1409.0473 (2014)*.\n",
    "\n",
    "4. Bai, T., Chanda, A. K., Egleston, B. L., & Vucetic, S. (2017). Joint learning of representations of medical concepts and words from ehr data. In *2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)*. IEEE, 764–769.\n",
    "\n",
    "5. Bai, T., Zhang, S., Egleston, B. L., & Vucetic, S. (2018). Interpretable Representation Learning for Healthcare via Capturing Disease Progression through Time. In *Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining*. ACM, 43–51.\n",
    "\n",
    "6. Baumel, T., Nassour-Kassis, J., Cohen, R., Elhadad, M., & Elhadad, N. (2017). Multi-label classification of patient notes a case study on ICD code assignment. *arXiv preprint arXiv:1709.09587* (2017).\n",
    "\n",
    "7. Choi, E., Bahadori, M. T., Schuetz, A., Stewart, W. F., & Sun, J. (2016). Doctor ai: Predicting clinical events via recurrent neural networks. In *Machine Learning for Healthcare Conference*. 301–318.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f08ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
